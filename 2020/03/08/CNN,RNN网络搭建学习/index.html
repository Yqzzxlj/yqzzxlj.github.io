<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>CNN,RNN网络搭建学习 | Yqzzxlj</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="代码来自于这里 提前划重点torchvision是独立于pytorch的关于图像操作的一些方便工具库 vision.datasets : 几个常用视觉数据集，可以下载和加载，这里主要的高级用法就是可以看源码如何自己写自己的Dataset的子类 vision.models : 流行的模型，例如 AlexNet, VGG, ResNet 和 Densenet 以及 与训练好的参数。 vision.tr">
<meta property="og:type" content="article">
<meta property="og:title" content="CNN,RNN网络搭建学习">
<meta property="og:url" content="http://yoursite.com/2020/03/08/CNN,RNN%E7%BD%91%E7%BB%9C%E6%90%AD%E5%BB%BA%E5%AD%A6%E4%B9%A0/index.html">
<meta property="og:site_name" content="Yqzzxlj">
<meta property="og:description" content="代码来自于这里 提前划重点torchvision是独立于pytorch的关于图像操作的一些方便工具库 vision.datasets : 几个常用视觉数据集，可以下载和加载，这里主要的高级用法就是可以看源码如何自己写自己的Dataset的子类 vision.models : 流行的模型，例如 AlexNet, VGG, ResNet 和 Densenet 以及 与训练好的参数。 vision.tr">
<meta property="og:locale" content="zh">
<meta property="article:published_time" content="2020-03-08T03:15:45.000Z">
<meta property="article:modified_time" content="2020-03-10T08:16:46.908Z">
<meta property="article:author" content="Yqzzxlj">
<meta property="article:tag" content="pytorch">
<meta name="twitter:card" content="summary">
  
  <link rel="stylesheet" href="//cdn.bootcss.com/highlight.js/9.2.0/styles/github.min.css">
  <script src="//cdn.bootcss.com/highlight.js/9.2.0/highlight.min.js"></script>
  <script>
    document.addEventListener('DOMContentLoaded', (event) => {
      document.querySelectorAll('pre code').forEach((block) => {
        hljs.highlightBlock(block);
      });
    });
  </script>
  
<link rel="stylesheet" href="/css/index.css">

<meta name="generator" content="Hexo 4.2.0"></head>

<body style="


  background-color: #eff0f6

">
  <div id="container">
    <nav id="nav">
  <header class="header">
    <a href="/" class="title">Yqzzxlj</a>
  </header>
  <div class="ctnWrap">
    <div class="icons">
      
        
          
            <a href="https://github.com/Yqzzxlj" target="_blank" class="nav-icn iconfont icon-github"></a>
          
        
      
    </div>
    <div class="menu">
      
        
            <a href="/" class="nav-menu ">HOME</a>
          
        
            <a href="/archives" class="nav-menu ">ARCHIVE</a>
          
        
            <a href="/tags" class="nav-menu ">TAG</a>
          
        
            <a href="/categories" class="nav-menu ">CATEGORY</a>
          
        
      
    </div>
  </div>
</nav>
    <div id="main"><section class="article">
  <h2 class="title">CNN,RNN网络搭建学习</h2>
  <p class="sub">Mar 8, 2020</p>
  <article class="content">
    <p>代码来自于<a href="https://github.com/MorvanZhou/PyTorch-Tutorial/tree/master/tutorial-contents" target="_blank" rel="noopener">这里</a></p>
<h2 id="提前划重点"><a href="#提前划重点" class="headerlink" title="提前划重点"></a>提前划重点</h2><h3 id="torchvision是独立于pytorch的关于图像操作的一些方便工具库"><a href="#torchvision是独立于pytorch的关于图像操作的一些方便工具库" class="headerlink" title="torchvision是独立于pytorch的关于图像操作的一些方便工具库"></a>torchvision是独立于pytorch的关于图像操作的一些方便工具库</h3><ul>
<li>vision.datasets : 几个常用视觉数据集，可以下载和加载，这里主要的高级用法就是可以看源码如何自己写自己的Dataset的子类</li>
<li>vision.models : 流行的模型，例如 AlexNet, VGG, ResNet 和 Densenet 以及 与训练好的参数。</li>
<li>vision.transforms : 常用的图像操作，例如：随机切割，旋转，数据类型转换，图像到tensor ,numpy 数组到tensor , tensor 到 图像等。</li>
<li>vision.utils : 用于把形似 (3 x H x W) 的张量保存到硬盘中，给一个mini-batch的图像可以产生一个图像格网。</li>
</ul>
<h3 id="以下CNN代码部分个人理解"><a href="#以下CNN代码部分个人理解" class="headerlink" title="以下CNN代码部分个人理解"></a>以下CNN代码部分个人理解</h3><pre><code class="python">train_data = torchvision.datasets.MNIST(
    root=&#39;./mnist/&#39;,
    train=True,                                     # this is training data
    transform=torchvision.transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to
                                                    # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]
    download=DOWNLOAD_MNIST,
)</code></pre>
<p>root参数是数据集本地路径<br>train为True时取训练集，False时取测试集<br>transform将原始数据转换为Tensor类型<br>download参数决定是否要下载数据集，如果有就不用下载了，设置为false</p>
<pre><code class="python">self.conv1 = nn.Sequential(         # input shape (1, 28, 28)
            nn.Conv2d(
                in_channels=1,              # input height
                out_channels=16,            # n_filters
                kernel_size=5,              # filter size
                stride=1,                   # filter movement/step
                padding=2,                  # if want same width and length of this image after Conv2d, padding=(kernel_size-1)/2 if stride=1
            ),                              # output shape (16, 28, 28)
            nn.ReLU(),                      # activation
            nn.MaxPool2d(kernel_size=2),    # choose max value in 2x2 area, output shape (16, 14, 14)
        )</code></pre>
<p>in_channels参数是height，在这里因为是灰度图所以通道数为1<br>out_channels为输出数通道数<br>stride步长<br>padding补零</p>
<pre><code class="python">test_output, _ = cnn(test_x[:10])
pred_y = torch.max(test_output, 1)[1].data.numpy()
print(pred_y, &#39;prediction number&#39;)
print(test_y[:10].numpy(), &#39;real number&#39;)</code></pre>
<p>训练网络之后的测试</p>
<h3 id="以下RNN代码部分个人理解"><a href="#以下RNN代码部分个人理解" class="headerlink" title="以下RNN代码部分个人理解"></a>以下RNN代码部分个人理解</h3><p>rnn网络在第t时刻隐藏层的输出需要t-1时刻的隐藏层的输出，可以解决一些带有时序序列的问题<br>LSTM相比rnn更有利于解决长输出问题，即重点信息在最开始出现。有输入门，输出门，忘记门的概念</p>
<pre><code class="python">INPUT_SIZE = 28 # 图片宽度为28，每一个step读取一个宽度的像素点
TIME_STEP = 28 # 图片为28 * 28, 每次读取28个像素点需要读取28个step</code></pre>
<pre><code class="python">class RNN(nn.Module):
    def __init__(self):
        super(RNN, self).__init__()

        self.rnn = nn.RNN(
            input_size=INPUT_SIZE,
            hidden_size=32,     # rnn hidden unit
            num_layers=1,       # number of rnn layer
            batch_first=True,   # input &amp; output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)
        )
        self.out = nn.Linear(32, 1)

    def forward(self, x, h_state):
        # x (batch, time_step, input_size)
        # h_state (n_layers, batch, hidden_size)
        # r_out (batch, time_step, hidden_size)
        r_out, h_state = self.rnn(x, h_state)

        outs = []    # save all predictions
        for time_step in range(r_out.size(1)):    # calculate output for each time step
            outs.append(self.out(r_out[:, time_step, :]))
        return torch.stack(outs, dim=1), h_state

        # instead, for simplicity, you can replace above codes by follows
        # r_out = r_out.view(-1, 32)
        # outs = self.out(r_out)
        # outs = outs.view(-1, TIME_STEP, 1)
        # return outs, h_state
        # or even simpler, since nn.Linear can accept inputs of any dimension
        # and returns outputs with same dimension except for the last
        # outs = self.out(r_out)
        # return outs</code></pre>
<p>具体参数的意义可以看<a href="https://pytorch.org/docs/stable/nn.html#lstm" target="_blank" rel="noopener">官网</a><br>在这里可以注意一下在处理图片时LSTM并没有用到之间的连接，返回值也是最后一个step的输入<br>而回归时用到了层与层之间的传递，初始化hstate为None.<br>注意在传递hstate时有一步hstate=hstate.data的操作<br>有一步用view函数reshape输入数据的操作</p>
<h2 id="CNN网络搭建（MNIST数据集）"><a href="#CNN网络搭建（MNIST数据集）" class="headerlink" title="CNN网络搭建（MNIST数据集）"></a>CNN网络搭建（MNIST数据集）</h2><p>代码</p>
<pre><code class="python"># standard library
import os

# third-party library
import torch
import torch.nn as nn
import torch.utils.data as Data
import torchvision
import matplotlib.pyplot as plt

# torch.manual_seed(1)    # reproducible

# Hyper Parameters
EPOCH = 1               # train the training data n times, to save time, we just train 1 epoch
BATCH_SIZE = 50
LR = 0.001              # learning rate
DOWNLOAD_MNIST = False


# Mnist digits dataset
if not(os.path.exists(&#39;./mnist/&#39;)) or not os.listdir(&#39;./mnist/&#39;):
    # not mnist dir or mnist is empyt dir
    DOWNLOAD_MNIST = True

train_data = torchvision.datasets.MNIST(
    root=&#39;./mnist/&#39;,
    train=True,                                     # this is training data
    transform=torchvision.transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to
                                                    # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]
    download=DOWNLOAD_MNIST,
)

# plot one example
print(train_data.train_data.size())                 # (60000, 28, 28)
print(train_data.train_labels.size())               # (60000)
plt.imshow(train_data.train_data[0].numpy(), cmap=&#39;gray&#39;)
plt.title(&#39;%i&#39; % train_data.train_labels[0])
plt.show()

# Data Loader for easy mini-batch return in training, the image batch shape will be (50, 1, 28, 28)
train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)

# pick 2000 samples to speed up testing
test_data = torchvision.datasets.MNIST(root=&#39;./mnist/&#39;, train=False)
test_x = torch.unsqueeze(test_data.test_data, dim=1).type(torch.FloatTensor)[:2000]/255.   # shape from (2000, 28, 28) to (2000, 1, 28, 28), value in range(0,1)
test_y = test_data.test_labels[:2000]


class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Sequential(         # input shape (1, 28, 28)
            nn.Conv2d(
                in_channels=1,              # input height
                out_channels=16,            # n_filters
                kernel_size=5,              # filter size
                stride=1,                   # filter movement/step
                padding=2,                  # if want same width and length of this image after Conv2d, padding=(kernel_size-1)/2 if stride=1
            ),                              # output shape (16, 28, 28)
            nn.ReLU(),                      # activation
            nn.MaxPool2d(kernel_size=2),    # choose max value in 2x2 area, output shape (16, 14, 14)
        )
        self.conv2 = nn.Sequential(         # input shape (16, 14, 14)
            nn.Conv2d(16, 32, 5, 1, 2),     # output shape (32, 14, 14)
            nn.ReLU(),                      # activation
            nn.MaxPool2d(2),                # output shape (32, 7, 7)
        )
        self.out = nn.Linear(32 * 7 * 7, 10)   # fully connected layer, output 10 classes

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = x.view(x.size(0), -1)           # flatten the output of conv2 to (batch_size, 32 * 7 * 7)
        output = self.out(x)
        return output, x    # return x for visualization


cnn = CNN()
print(cnn)  # net architecture

optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)   # optimize all cnn parameters
loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted

# following function (plot_with_labels) is for visualization, can be ignored if not interested
from matplotlib import cm
try: from sklearn.manifold import TSNE; HAS_SK = True
except: HAS_SK = False; print(&#39;Please install sklearn for layer visualization&#39;)
def plot_with_labels(lowDWeights, labels):
    plt.cla()
    X, Y = lowDWeights[:, 0], lowDWeights[:, 1]
    for x, y, s in zip(X, Y, labels):
        c = cm.rainbow(int(255 * s / 9)); plt.text(x, y, s, backgroundcolor=c, fontsize=9)
    plt.xlim(X.min(), X.max()); plt.ylim(Y.min(), Y.max()); plt.title(&#39;Visualize last layer&#39;); plt.show(); plt.pause(0.01)

plt.ion()
# training and testing
for epoch in range(EPOCH):
    for step, (b_x, b_y) in enumerate(train_loader):   # gives batch data, normalize x when iterate train_loader

        output = cnn(b_x)[0]               # cnn output
        loss = loss_func(output, b_y)   # cross entropy loss
        optimizer.zero_grad()           # clear gradients for this training step
        loss.backward()                 # backpropagation, compute gradients
        optimizer.step()                # apply gradients

        if step % 50 == 0:
            test_output, last_layer = cnn(test_x)
            pred_y = torch.max(test_output, 1)[1].data.numpy()
            accuracy = float((pred_y == test_y.data.numpy()).astype(int).sum()) / float(test_y.size(0))
            print(&#39;Epoch: &#39;, epoch, &#39;| train loss: %.4f&#39; % loss.data.numpy(), &#39;| test accuracy: %.2f&#39; % accuracy)
            if HAS_SK:
                # Visualization of trained flatten layer (T-SNE)
                tsne = TSNE(perplexity=30, n_components=2, init=&#39;pca&#39;, n_iter=5000)
                plot_only = 500
                low_dim_embs = tsne.fit_transform(last_layer.data.numpy()[:plot_only, :])
                labels = test_y.numpy()[:plot_only]
                plot_with_labels(low_dim_embs, labels)
plt.ioff()

# print 10 predictions from test data
test_output, _ = cnn(test_x[:10])
pred_y = torch.max(test_output, 1)[1].data.numpy()
print(pred_y, &#39;prediction number&#39;)
print(test_y[:10].numpy(), &#39;real number&#39;)</code></pre>
<h2 id="RNN分类网络（MNIST数据集）"><a href="#RNN分类网络（MNIST数据集）" class="headerlink" title="RNN分类网络（MNIST数据集）"></a>RNN分类网络（MNIST数据集）</h2><p>代码</p>
<pre><code class="python">import torch
from torch import nn
import torchvision.datasets as dsets
import torchvision.transforms as transforms
import matplotlib.pyplot as plt


# torch.manual_seed(1)    # reproducible

# Hyper Parameters
EPOCH = 1               # train the training data n times, to save time, we just train 1 epoch
BATCH_SIZE = 64
TIME_STEP = 28          # rnn time step / image height
INPUT_SIZE = 28         # rnn input size / image width
LR = 0.01               # learning rate
DOWNLOAD_MNIST = True   # set to True if haven&#39;t download the data


# Mnist digital dataset
train_data = dsets.MNIST(
    root=&#39;./mnist/&#39;,
    train=True,                         # this is training data
    transform=transforms.ToTensor(),    # Converts a PIL.Image or numpy.ndarray to
                                        # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]
    download=DOWNLOAD_MNIST,            # download it if you don&#39;t have it
)

# plot one example
print(train_data.train_data.size())     # (60000, 28, 28)
print(train_data.train_labels.size())   # (60000)
plt.imshow(train_data.train_data[0].numpy(), cmap=&#39;gray&#39;)
plt.title(&#39;%i&#39; % train_data.train_labels[0])
plt.show()

# Data Loader for easy mini-batch return in training
train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)

# convert test data into Variable, pick 2000 samples to speed up testing
test_data = dsets.MNIST(root=&#39;./mnist/&#39;, train=False, transform=transforms.ToTensor())
test_x = test_data.test_data.type(torch.FloatTensor)[:2000]/255.   # shape (2000, 28, 28) value in range(0,1)
test_y = test_data.test_labels.numpy()[:2000]    # covert to numpy array


class RNN(nn.Module):
    def __init__(self):
        super(RNN, self).__init__()

        self.rnn = nn.LSTM(         # if use nn.RNN(), it hardly learns
            input_size=INPUT_SIZE,
            hidden_size=64,         # rnn hidden unit
            num_layers=1,           # number of rnn layer
            batch_first=True,       # input &amp; output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)
        )

        self.out = nn.Linear(64, 10)

    def forward(self, x):
        # x shape (batch, time_step, input_size)
        # r_out shape (batch, time_step, output_size)
        # h_n shape (n_layers, batch, hidden_size)
        # h_c shape (n_layers, batch, hidden_size)
        r_out, (h_n, h_c) = self.rnn(x, None)   # None represents zero initial hidden state

        # choose r_out at the last time step
        out = self.out(r_out[:, -1, :])
        return out


rnn = RNN()
print(rnn)

optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters
loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted

# training and testing
for epoch in range(EPOCH):
    for step, (b_x, b_y) in enumerate(train_loader):        # gives batch data
        b_x = b_x.view(-1, 28, 28)              # reshape x to (batch, time_step, input_size)

        output = rnn(b_x)                               # rnn output
        loss = loss_func(output, b_y)                   # cross entropy loss
        optimizer.zero_grad()                           # clear gradients for this training step
        loss.backward()                                 # backpropagation, compute gradients
        optimizer.step()                                # apply gradients

        if step % 50 == 0:
            test_output = rnn(test_x)                   # (samples, time_step, input_size)
            pred_y = torch.max(test_output, 1)[1].data.numpy()
            accuracy = float((pred_y == test_y).astype(int).sum()) / float(test_y.size)
            print(&#39;Epoch: &#39;, epoch, &#39;| train loss: %.4f&#39; % loss.data.numpy(), &#39;| test accuracy: %.2f&#39; % accuracy)

# print 10 predictions from test data
test_output = rnn(test_x[:10].view(-1, 28, 28))
pred_y = torch.max(test_output, 1)[1].data.numpy()
print(pred_y, &#39;prediction number&#39;)
print(test_y[:10], &#39;real number&#39;)</code></pre>
<h2 id="RNN回归网络"><a href="#RNN回归网络" class="headerlink" title="RNN回归网络"></a>RNN回归网络</h2><p>代码</p>
<pre><code class="python">import torch
from torch import nn
import numpy as np
import matplotlib.pyplot as plt

# torch.manual_seed(1)    # reproducible

# Hyper Parameters
TIME_STEP = 10      # rnn time step
INPUT_SIZE = 1      # rnn input size
LR = 0.02           # learning rate

# show data
steps = np.linspace(0, np.pi*2, 100, dtype=np.float32)  # float32 for converting torch FloatTensor
x_np = np.sin(steps)
y_np = np.cos(steps)
plt.plot(steps, y_np, &#39;r-&#39;, label=&#39;target (cos)&#39;)
plt.plot(steps, x_np, &#39;b-&#39;, label=&#39;input (sin)&#39;)
plt.legend(loc=&#39;best&#39;)
plt.show()


class RNN(nn.Module):
    def __init__(self):
        super(RNN, self).__init__()

        self.rnn = nn.RNN(
            input_size=INPUT_SIZE,
            hidden_size=32,     # rnn hidden unit
            num_layers=1,       # number of rnn layer
            batch_first=True,   # input &amp; output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)
        )
        self.out = nn.Linear(32, 1)

    def forward(self, x, h_state):
        # x (batch, time_step, input_size)
        # h_state (n_layers, batch, hidden_size)
        # r_out (batch, time_step, hidden_size)
        r_out, h_state = self.rnn(x, h_state)

        outs = []    # save all predictions
        for time_step in range(r_out.size(1)):    # calculate output for each time step
            outs.append(self.out(r_out[:, time_step, :]))
        return torch.stack(outs, dim=1), h_state

        # instead, for simplicity, you can replace above codes by follows
        # r_out = r_out.view(-1, 32)
        # outs = self.out(r_out)
        # outs = outs.view(-1, TIME_STEP, 1)
        # return outs, h_state
        # or even simpler, since nn.Linear can accept inputs of any dimension
        # and returns outputs with same dimension except for the last
        # outs = self.out(r_out)
        # return outs

rnn = RNN()
print(rnn)

optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters
loss_func = nn.MSELoss()

h_state = None      # for initial hidden state

plt.figure(1, figsize=(12, 5))
plt.ion()           # continuously plot

for step in range(100):
    start, end = step * np.pi, (step+1)*np.pi   # time range
    # use sin predicts cos
    steps = np.linspace(start, end, TIME_STEP, dtype=np.float32, endpoint=False)  # float32 for converting torch FloatTensor
    x_np = np.sin(steps)
    y_np = np.cos(steps)

    x = torch.from_numpy(x_np[np.newaxis, :, np.newaxis])    # shape (batch, time_step, input_size)
    y = torch.from_numpy(y_np[np.newaxis, :, np.newaxis])

    prediction, h_state = rnn(x, h_state)   # rnn output
    # !! next step is important !!
    h_state = h_state.data        # repack the hidden state, break the connection from last iteration

    loss = loss_func(prediction, y)         # calculate loss
    optimizer.zero_grad()                   # clear gradients for this training step
    loss.backward()                         # backpropagation, compute gradients
    optimizer.step()                        # apply gradients

    # plotting
    plt.plot(steps, y_np.flatten(), &#39;r-&#39;)
    plt.plot(steps, prediction.data.numpy().flatten(), &#39;b-&#39;)
    plt.draw(); plt.pause(0.05)

plt.ioff()
plt.show()</code></pre>

  </article>
  <footer class="f-cf">
    
      <a href="/2020/03/10/%E8%87%AA%E7%BC%96%E7%A0%81%E3%80%81DQN%E3%80%81GAN%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0/" class="link f-fl">⟵自编码、DQN、GAN网络学习</a>
    
    
      <a href="/2020/03/07/%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8Pytorch/" class="link f-fr">学习使用Pytorch⟶</a>
    
  </footer>
</section></div>
    <footer id="footer" class="f-cf">
  1186859107@qq.com
  
    
      
        · <a href="https://github.com/Yqzzxlj" target="_blank" class="nav-icn">GitHub</a>
      
    
  
  <span class="copyright">All rights reserved @Yqzzxlj</span>
</footer>
  </div>
</body>
</html>