---
title: 服务器项目总结
date: 2021-03-05 22:15:36
tags:
    - c++
    - HTTP
    - 项目
categories:
    - 项目相关
---
# Tiny Web Server 服务器项目整理总结

### 1. Reactor模型

主线程（I/O处理单元）只负责监听文件描述上是否有事件发生，有的话就立即将该事件通知工作线程（逻辑单元）。除此之外，主线程不做任何其他实质性的工作。读写数据，接受新的连接，以及处理新的连接，以及处理客户请求均在工作线程中完成。

1. 主线程往epoll内核事件表中注册socket上的读就绪事件。
2. 主线程调用epoll_wait等待socket上有数据可读。
3. 当socket上有数据可读时，epoll_wait通知主线程。主线程则将socket可读事件放入请求队列。
4. 睡眠在请求队列上的某个工作线程被唤醒，他从socket读取数据并处理客户请求，然后往epoll内核事件表中注册该socket上的写就绪事件。
5. 主线程调用epoll_wait()等待socket可写。
6. 当socket可写时，epoll_wait通知主线程。主线程将socket可写事件放入请求队列。
7. 睡眠在请求队列上的某个工作线程被唤醒，它往socket上写入服务器处理客户请求的结果。

### 2. 线程池

+ 资源重用，避免了线程频繁建立、关闭的开销
+ 控制资源的使用。如果不使用池，每次都需要创建一个线程，这样系统的稳定性受系统连接需求影响很大，很容易产生资源浪费和高负载异常。池能够使性能最大化，将资源利用控制在一定的水平之下。连接池能控制池中的连接数量，增强了系统在大量用户应用时的稳定性。
+ 实现：构造、析构、任务enqueue

```c++
#pragma once
#include <vector>
#include <queue>

#include <mutex>
#include <condition_variable>
#include <thread>
#include <functional>
#include <future>
#include <memory>
#include <stdexcept>

class ThreadPool {
public:
  ThreadPool(size_t);
  ~ThreadPool();

  template<typename F, typename... Args>
  auto enqueue(F&&f, Args&&... args)
    -> std::future<typename std::result_of<F(Args...)>::type>;

private:
  std::vector<std::thread> workers;
  std::queue<std::function<void()>> tasks;

  std::mutex queue_mutex;
  std::condition_variable condition;
  bool stop;
};

inline ThreadPool::ThreadPool(size_t num_threads) : stop(false) {
  for (size_t i = 0; i < num_threads; ++i) {
    workers.emplace_back(
      [this](){
        while(true) {
          std::function<void()> task;
          {
            std::unique_lock<std::mutex> lock(this->queue_mutex);
            this->condition.wait(lock,
              [this](){return this->stop || !this->tasks.empty();});
            if (this->stop && this->tasks.empty()) {
              return;
            }
            task = std::move(this->tasks.front());
            this->tasks.pop();
          }
          task();
        }
      }
    );
  }
}

inline ThreadPool::~ThreadPool() {
  {
    std::unique_lock<std::mutex> lock(queue_mutex);
    stop = true;
  }
  condition.notify_all();
  for (std::thread& worker : workers) {
    worker.join();
  }
}

template<typename F, typename... Args>
auto ThreadPool::enqueue(F&& f, Args&&... args)
  -> std::future<typename std::result_of<F(Args...)>::type> {

  using return_type = typename std::result_of<F(Args...)>::type;

  auto task = std::make_shared<std::packaged_task<return_type()>> (
    std::bind(std::forward<F>(f), std::forward<Args>(args)...)
  );

  std::future<return_type> res = task->get_future();
  {
    std::unique_lock<std::mutex> lock(queue_mutex);
    if (stop) {
      throw std::runtime_error("enqueue on stopped ThreadPool");
    }
    tasks.emplace([task](){(*task)();});
  }
  condition.notify_one();
  return res;
}
```

### 3. 状态机解析HTTP请求

LINE_STATE， PARSE_STATE, HTTP_CODE

```c++
	enum LINE_STATE {LINE_OK = 0, LINE_BAD, LINE_MORE};
  enum PARSE_STATE {PARSE_REQUESTLINE = 0, PARSE_HEADER, PARSE_BODY};
  enum HTTP_CODE {NO_REQUEST = 0, GET_REQUEST, BAD_REQUEST, NOT_IMPLEMNTED, 
                  FORBIDDEN_REQUEST, INTERNAL_ERROR, CLOSED_CONNECTION};

  static LINE_STATE parse_line(Buffer& buffer);
  static HTTP_CODE parse_request_line(const std::string&, PARSE_STATE&, HttpRequest&);
  static HTTP_CODE parse_headers(const std::string&, PARSE_STATE&, HttpRequest&);
  static HTTP_CODE parse_body(const std::string&, HttpRequest&);
  static HTTP_CODE parse_content(Buffer& buffer, PARSE_STATE &parse_state, HttpRequest& request);
```

### 4. 定时器结构

最小堆实现。

每一个TimerNode包含一个expired Time，和Httpdata的指针，

有一个_deleted字段支持惰性删除。



#### 实现定时器的其他方式

升序链表、时间轮

### 5. 双缓冲区技术实现异步日志系统

#### 为什么要一个日志系统？

 记录系统状态，方便查找出错原因

#### 为什么要是实现一个日志系统？

stdio在使用上不便，容易出现缓冲区溢出、格式字符串混淆等错误，而且很难保证类型安全。不可扩展。

iostream是可扩展的类型安全的IO机制。但是ostream格式化输出繁琐，istream不适合输入带格式的数据，线程不安全，不适合在多线程程序中做logging。

应该使用成熟的多线程库。

#### 双缓冲区？

准备两块buffer，一块写入日志消息，一块将消息写入文件。 

#### 实现

用一个线程负责收集日志消息并写入文件，其他业务线程只管往这个“日志线程”发送消息，这称为异步日志。

多生产者-单消费者问题，对于生产者而言，要尽量做到低延迟，低cpu开销，无阻塞；对消费者而言要做到足够大的吞吐量，并占用较少资源。

+ FileUtil 封装了文件的打开，关闭，写入。
+  LogFile 在FileUtil的基础上，加了锁，和按写次数flush。
+ LogStream 重载operator<<,将内容存在自己的缓存中。
+  AsyncLogging 启动一个log线程，负责定时或缓冲区填满时，将log写入logFile。双缓冲交换指针。
+  Logging 是对外接口，内含一个LogStream，将内容输入到LogStream的buffer中，并有一个静态的AsyncLogger， 向日志文件内写内容。实现了日志等级

### 6. RAII机制

资源获得即初始化。

智能指针、unique_lock、fd（socket）

### 7. 压测

Webbench。4内核、4G内存。1000clients，60s，QPS 36621

### 8. 一个请求到来的处理过程

启动：服务器listen_fd, 新建线程池，和epoll_fd。 令epoll监听listen_fd.

请求到来：connect，epoll通知事件就绪，将client_socket设置非阻塞，Nodelay（禁用nagle算法），将fd和httpData绑定，然后重新加入epoll，添加定时器。将处理连接请求的函数推入线程池的任务队列。

处理请求：

+ 从socket中读取数据，逐步分析请求行（方法，url，版本）首部行，空行，实体主体。
+ 如果是HEAD请求，发送头部，如果是GET，除了头部之外在发送指定文件。（共享内存，mmap，munmap）
+ 如果是短链接则直接关闭，长连接重新添加定时器，再次令epoll监听fd

### 9 遇到的问题

1. webbench测试完就会宕机。

连接建立，若某一端关闭连接，而另一端仍然向它写数据，第一次写数据后会收到RST响应，此后再写数据，内核将向进程发出SIGPIPE信号，通知进程此连接已经断开。而SIGPIPE信号的默认处理是终止程序，导致上述问题的发生。应该忽略SIGPIPE信号。

### 10. 为什么用非阻塞IO

- 水平触发：只要缓冲区有数据准备好就传递就绪信号
- 边缘触发：只有新数据到来才会传递就绪信号，没有新数据到来时尽管有旧数据没有呗读取也不通知

ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。

### 11. 无锁队列

CAS

