---
title: 教发项目总结
date: 2021-03-05 22:55:16
tags:
    - python
    - Django
    - 项目
categories:
    - 项目相关
---
### 1. 介绍一下项目

### 2. Django 

#### 2.1 对Django的认识

- Django是走大而全的方向，它是出名的自动化管理后台，只需要使用ORM，简单的对象定义，自动生成数据库结构，全功能的管理后台。
- Django内置了一个ORM框架，与其其他模块耦合性较高，理论上必须使用该框架
- Django的最大优势是开发效率高，Django项目达到一定规模后需要重构才能满足性能需求
- 适用于中小型网站或大型网站的雏形
- Django模版设计哲学是彻底将代码、样式分离

#### 2.2 MVC模型和MTV模型

1. MVC模型（model，view，controller）

所谓MVC就是把应用分为模型、控制器、视图三层，以插件式、松耦合的方式放在一起，

- 模型负责对象与数据库的映射（ORM）
- 视图负责与用户的交互（页面）
- 控制器接受用户调入模型和视图完成用户请求。

2. MTV模型（model，template，view）

Django的MTV模式本质上和MVC是一样的，也是为了各组件间保持松耦合关系，只是定义上有些许不同：

- 模型：编写程序应有的功能，负责业务对象与数据库的映射（ORM）
- 模版：负责如何把页面（html）展示给用户。
- 视图：负责业务逻辑，并在适当时候调用Model和Template。

除了以上三层之外，还需要一个URL分发器，他的作用是将一个个URL的页面请求分发给不同的View处理，View在调用相应的Model和Template。

#### 2.3 Django 请求的生命周期

一般用户通过浏览器发送请求，这个请求访问视图函数，视图函数调用模型，模型去数据库查找数据，然后逐级返回，再填充到模板最后返回给用户。

- wsgi，请求封装后交给web框架（flask、Django）
- 中间件，对请求进行校验后在请求中添加相关数据（如csrf、session）
- 路由匹配，根据浏览器发送的不同URL去匹配不同的函数
- 视图函数，视图函数中进行业务处理，可能涉及到ORM和模板渲染
- 中间件，对响应函数进行处理
- wsgi，将响应内容发给浏览器

#### 2.4 ORM

ORM是对象关系映射，是MVC框架的一个重要部分。它实现了数据模型与数据的结偶，即数据模型的设计不依赖特定的数据库，通过简单的配置就可以更换数据库，极大地减轻了开发人员的工作量。

Django 就让开发者 通过 类 和 实例的操作 来对应 数据库 表 和记录的操作。

select_relect(), 外键查询，通过JOIN语句减少查询次数

prefetch_relect()，多对多，多对一，缓存，在通过python语句查询，减少查询数据库的次数。

#### 2.5 中间件

Django中间件是修改Django request或者response对象的钩子，可以理解为是介于HttpRequest与HttpResponse处理之间的一道处理过程。浏览器从请求到响应的过程中，Django需要通过很多中间件来处理。

它是一个轻量，低级别的插件系统，用于在全局范围改变Django的输入和输出，每个中间件负责一些特定功能。

中间件和拦截一部分请求，比如验证session，没有登陆的进行跳转

#### 2.6 Django的查询特性

- 惰性执行、缓存
- 创建查询集不会访问数据库，直到使用数据时才会访问数据库，调用数据的情况包括迭代、序列化、与if合用。

#### 2.7 什么是wsgi、uwsgi、uWSGI

WSGI：web服务器的网关接口(Web Server Gateway Interface)，是一套协议，用于接受用户请求并进行初次封装，然后交给web服务器。

> 遵循wsgi规范的 web后端系统， 我们可以理解为 由两个部分组成
>
> wsgi web server 和 wsgi web application
>
> 它们通常是运行在一个python进程中的两个模块，或者说两个子系统。
>
> wsgi web server 接受到前端的http请求后，会调用 wsgi web application 的接口（ 比如函数或者类方法）方法，由wsgi web application 具体处理该请求。然后再把处理结果返回给 wsgi web server， wsgi web server再返回给前端。 wsgi web server 负责 提供高效的http请求处理环境，可以使用多线程、多进程或者协程的机制。

> http 请求发送到 wsgi web server ， wsgi web server 分配 线程或者进程或者 轻量级线程(协程)，然后在 这些 线程、进程、或者协程里面，去调用执行 wsgi web application 的入口代码。

> wsgi web application 被调用后，负责 处理 业务逻辑。 业务逻辑的处理可能非常复杂， wsgi web application 需要精心的设计来正确处理。

> django是 wsgi web application 的框架，它只有一个简单的单线程 wsgi web server。 供调试时使用。

> 产品正式上线运行的时候，通常我们需要高效的 wsgi web server 产品，比如 gunicorn，uwsgi，cherrypy等，结合Django ，组成一个高效的 后端服务。

> 所以这个 [wsgi.py](http://wsgi.py) 就是 提供给wsgi web server调用 的接口文件，里面的变量application对应对象实现了 wsgi入口，供wsgi web server调用 。

实现wsgi协议的模块：

1. wsgiref本质上是一个socket服务器，用于接受用户请求（django）
2. werkzeug本质上是一个socket服务器，用于接受用户请求（flask）

而uswgi也是一种通信协议

uWSGI是一个web服务器，实现了上述协议。

#### 2.8 对restful的理解

restful是一套编写接口的协议，协议规定如何编写url及如何设置返回值，状态信息码等。

以不同方法请求不同url产生的动作是不一样的。HTTPS、域名/api

### 3. Docker

#### 3.1 使用docker的好处

将代码和其环境打包在一起，

#### 3.2 基本组成

客户端、服务器、仓库

#### 3.3 和虚拟机的区别

容器与虚拟机拥有着类似的使命：对应用程序及其关联性进行隔离，从而构建起一套能够随处运行的自容纳单元。

此外，容器与虚拟机还摆脱了对物理硬件的需求，允许我们更为高效地使用计算资源，从而提升能源效率与成本效益。

容器与虚拟机之间的核心差异在于其架构方法。

- 虚拟机资源占用多，启动慢，冗余步骤多
- 传统虚拟机会虚拟出一份硬件，运行一个完整的操作系统，然后在这个系统上安装和运行软件
- docker每个容器都有自己的文件系统，互相隔离。docker内的应用直接运行在宿主机，容器没有自己的内核，也没有虚拟硬件，所以更加轻便。



### 4. Redis

#### 4.1 底层

简单动态字符串、链表、字典、跳跃表、整数集合、压缩列表

#### 4.2 对象

字符串、列表、哈希、集合、有序集合（跳跃表+字典）

#### 4.3 键的过期时间

Redis可以为每个键设置过期时间，当键过期时，会自动删除该键。

对于散列表这种容器，只能为整个键设置过期时间（整个散列表），而不能为键里面的单个元素设置过期时间。

##### 4.3.1 过期键的删除策略

1. 定时删除：在设置键的过期时间的通过，创建一个定时器（timer），让定时器在键的过期时间来临时，立即执行对键的删除操作。（对内存最友好，对CPU时间不友好）
2. 惰性删除：放任键过期不管，但是每次从键空间中获取键时，都检查取得的键是否过期，如果过期就删除;如果没有过期就返回：
3. 定期删除：每隔一段时间，程序就对数据库进行一次检查，删除里边的过期键。

##### 4.3.2AOF、RDB 和复制功能对过期键的处理

- 执行SAVE命令或者BGSAVE命令所产生的新RDB文件不会包含已经过期的键
- 执行BGREWRITEAOF命令所产生的重写AOF文件不会包含已经过期的键
- 当一个过期键被删除后，服务器会追加一条DEL命令到现有AOF文件的末尾，显式的删除过期键。
- 当主服务器删除一个过期键之后，服务器会追加一条DEL命令到现有AOF文件的末尾，显式的删除过期键。
- 从服务器即使发现过期键也不会自作主张地删除它，而是等待主节点发来DEL命令，这种统一、中心化的过期键删除策略可以保证主从服务器数据的一致性。

#### 4.4 为什么用NOSQL

超大规模的高并发的社区，传统的关系型数据库很难应对。

个人信息，社交网络，地理位置等不能用固定的格式。所以用NoSQL

1. 方便扩展
2. 大数据量高性能
3. 数据类型多样。不需要事先设计数据库

- 传统的关系型数据库RDBMS
  1. 结构化组织（行，列）
  2. SQL
  3. 数据和关系都存在单独的表中
  4. 严格的一致性
  5. 基础的事务
- NoSQL
  1. 不仅仅是数据
  2. 没有固定的查询语言
  3. 键值对存储
  4. 最终一致性
  5. CAP定理和BASE理论 （异地多活）
  6. 高性能、高可用、高可扩展
- CAP
  1. P 分区容错性
  2. C 一致性
  3. A 可用性
- BASE
  1. BA 基本可用：出现了不可预知的故障时仍然可用。相比正常的系统而言会有响应时间上的损失和功能上的损失（页面降级）
  2. S 软状态：允许数据中的数据存在中间状态，并认为该状态不影响系统的整体可用性，即允许系统在多个不同节点的数据副本存在数据延时
  3. E 最终一致性：在软状态的期限过后，应当保证所有副本保持数据一致性，这个时间期限取决于网络延时，系统负载、数据复制方案设计等等因素。
- 应用场景
  - 计数器：对string进行自增自减运算，从而实现计数器功能
  - 缓存：将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。
  - 查找表：查找表和缓存类似，也是利用了Redis快速的查找特性。但是查找表的内容不能失效，因为缓存不作为可靠的数据来源。
  - 消息队列：List是一个双向链表，可以通过lpush和rpop写入和读取消息。
  - 会话缓存：可以使用Redis来统一存储多台应用服务器的会话信息。当应用服务器不在存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。
  - 分布式锁：在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。可以使用Redis自带的SETNX命令实现分布式锁
  - 共同好友：Set
  - 排行榜：ZSet

#### 4.5 字典

dictht是一个散列表结构，使用拉链法解决哈希冲突。

Redis的字典dict中包含两个哈希表dictht，这是为了方便进行rehash操作。在扩容时，将其中一个dictht上的键值对rehash到另一个dichht上面，完成之后释放空间并交换两个dictht的角色。

rehash操作不是一次性完成，而是渐进方式，这是为了避免一次性执行过多的rehash操作给服务器带来过大的负担。

渐进式rehash通过记录dict的rehashidx完成，它从0开始，然后每执行一次rehash都会递增。例如在一次rehash中，要把dict[0]rehash到dict[1]，这一次会把dict[0]上table[rehashidx]的键值对rehash到dict[1]上，dict[0]的table【rehashidx指向null，并令rehashidx++。

在rehash期间，每次对字典执行添加、删除、查找或者更新操作时，都会执行一次渐进式rehash。

采用渐进式rehash会导致字典中的数据分散在两个dictht上，因此对字典的查找操作也需要到对应的dictht去执行。

#### 4.6 跳跃表

是有序集合的底层实现之一。

+ 跳跃表通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。
+ 跳跃表支持平均O(logN)、最坏O(N)复杂度的节点查找，还可以通过顺序性操作来批量处理节点。



当元素数量比较多或者成员是比较长的字符串的时候Redis会用跳跃表来实现有序集合：

跳跃表在链表的基础上增加了多级索引以提升查找的效率，这是一个用空间换时间的方案，因为索引是占内存的。原始链表中存储的有可能是很大的对象，而索引结点只需要存储关键值值和几个指针，并不需要存储对象，因此当节点本身比较大或者元素数量比较多的时候，其优势必然会被放大，而缺点则可以忽略。



与红黑树等平衡树相比，跳跃表具有以下优点：

- 插入速度非常快速，因为不需要进行旋转等操作来维护平衡性；
- 更容易实现

#### 跳跃表的实现

每次创建一个新跳跃表节点的时候，程序都会根据幂次定律随机生成一个介于1和32之间的值作为

```c
typedef struct zskiplistNode {
  // 后退指针
  struct zskiplistNode* backward;
  
  // 分值
  double score;
  
  // 成员对象
  robj* obj;
  
  // 层
  struct zskiplistLevel {
    // 前进指针
    struct zskiplistNode* forward;
    
    //  跨度,指向NULL的跨度为0，用来计算排位
    unsigned int span;
  } level[];
} zskiplistNode;

typedef struct zskiplist {
  // 表头节点和表尾节点
  struct zskiplistNode *header, *tail;
  
  // 表中节点的数量
  unsigned long length;
  
  // 表中层数最大的节点的层数
  int level;
}
```

#### 4.7 压缩列表

连续内存块组成的顺序性数据结构。由尾部向首部遍历。

由于previous_entry_length的变化可能会引发连锁更新。

实现

+ 节点：previois_entry_length + encoding + content
+ 列表：zlbytes + zltail + Allen + entry1 + ... + entry + lend 

#### 4.8 事务

1. Redis单条命令保证原子性，但是事务不保证原子性。 编译型错误，都不执行。 运行时错误，出错的不执行
2. Redis事务不存在隔离级别的概念。

- 开启事务
- 命令入队
- 执行事务

watch监视变量是否被其他线程修改 unwatch

一个事务包含了多个命令，服务器在执行事务期间，不会改去执行其他客户端的命令请求。

事务中的多个命令被一次性发送给服务器，而不是一条一条发送，这种方式被称为流水线，它可以减少客户端与服务器之间的网络通信次数从而提升性能

Redis最简单的事务实现方式是使用MULTI和ECEC命令将事务操作包围起来。discard放弃。

#### 4.9 数据淘汰策略

可以设置内存最大使用量，当内存使用量超出时，会施行数据淘汰策略。

Redis具体有6种淘汰策略：


| 策略            | 描述                                                 |
| --------------- | ---------------------------------------------------- |
| volatile-lru    | 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 |
| volatile-ttl    | 从已设置过期时间的数据集中挑选将要国旗的数据淘汰     |
| volatile-random | 从已设置过期时间的数据集中任意选择数据淘汰           |
| allkeys-lru     | 从所有数据集中挑选最近最少使用的数据淘汰             |
| allkeys-random  | 从所有数据集中任意选择数据进行淘汰                   |
| norviction      | 禁止驱逐数据                                         |

#### 4.10 持久化

Redis是内存型数据库，为了保证数据在断电后不会丢失，需要将内存中的数据持久化到硬盘上。

##### RDB

+ 将某个时间点的所有数据都存放到硬盘上
+ 可以将快照复制到其他服务器从而创建具有相同数据的服务器副本。
+ 如果系统发生故障，将会丢失最后一次创建快照之后的数据。
+ 如果数据量很大，保存快照的时间会很长。

##### AOF

将写命令添加到AOF文件（Append Only File）的末尾

使用AOF持久化粗腰设置同步选项，从而确保写命令同步到磁盘文件上的时机。这是因为对文件进行写入并不会马上将内容同步到磁盘上，而是先存储到缓存区，然后有操作系统决定什么时候同步到磁盘。有以下同步选项：


| 选项     | 同步频率                 |
| -------- | ------------------------ |
| always   | 每个写命令都同步         |
| everysec | 每秒同步一次             |
| no       | 让操作系统来决定何时同步 |

+ always 选项会严重减低服务器的性能
+ everysec选项比较合适，可以保证系统崩溃时只会丢失一秒左右的数据，并且Redis每秒执行一次同步对服务器性能几乎没有任何影响
+ no 选项并不能给服务器性能带来多大的提升，而且也会增加系统崩溃时数据丢失的数量。

随着服务器写请求的增多，AOF文件会越来越大。Redis提供了一种将AOF重写的特性，能够去除AOF文件中的冗余写命令。

#### 4.11 Redis为什么快

1. IO多路复用
2. 数据结构简单，操作节省时间
3. 运行在内存中

#### 4.12 主从复制

##### 连接过程

##### 主从链

#### 4.13 缓存击穿、缓存穿透、缓存雪崩

+ 缓存穿透：key对应的数据源并不存在，每次针对此key的请求从缓存获取不到，请求都会到数据源，从而可能压垮数据源。比如用一个不存在的用户id获取用户信息，不论缓存还是数据库都没有，若黑客利用此漏洞进行攻击可能压垮数据库。解决方法：1. 采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。2. **另外也有一个**更为简单粗暴的方法（我们采用的就是这种），如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。

+ 缓存击穿：key对应的数据存在，但在redis中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。

  SETNX，是「SET if Not eXists」的缩写，也就是只有不存在的时候才设置，可以利用它来实现锁的效果。

+ 缓存雪崩：当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，也会给后端系统(比如DB)带来很大压力。多数系统设计者考虑用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。还有一个简单方案就时讲缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。

#### 4.14 和Memcached的区别

二者都是非关系性内存键值数据库，

+ 数据类型：Redis支持五种不同的数据类型，Memcached仅支持字符串类型
+ 数据持久化：Redis支持两种持久化策略，Memcached不支持持久化
+ 分布式：Redis Cluster实现了分布式的支持，Memcached不支持分布式，只能通过在客户端使用一致性哈希来实现分布式存储
+ 内存管理机制：Memcached的数据则会一直在内存中，Memcached将内存分割成特定长度的块来存储数据。但是这种方式会使得内存的利用率不高

### 5. Nginx

#### 5.1 Nginx概述（多进程单线程）

https://www.cnblogs.com/mmdln/p/8952261.html https://www.cnblogs.com/gccbuaa/p/6795229.html

Nginx(engine x)是一款轻量级、高性能的Web服务器/反向代理服务器及电子邮件(IMAP/POP3)代理服务器，并在一个BSD-like协议下发行。

- 跨平台、配置简单
- 非阻塞，高并发连接 如果作为web服务器，nginx能够支持高达50000的并发连接数
- 内存消耗小，10个nginx才占用150M内存
- 处理静态文件好，耗费内存少
- 一个master进程生成多个worker进程，
- 多进程异步非阻塞事件处理机制（epoll模型）
- 内置的健康检查功能：如果有一个服务器宕机，会做一个健康检查，再发送的请求就不会发送到宕机的服务器了。重新将请求提交到其他的节点上。
- 可以有多台nginx服务器

#### 5.2 Nginx的负载均衡算法

- round robin（轮询，默认） 每个请求按照一定的时间顺序逐一分配到不同的后端服务器
- weight 指定轮询的几率， 和访问比例呈正比，用于性能不均的情况。 加权轮询算法分为先深搜索和先广搜索，那么nginx采用的是先深搜索算法，即将首先将请求都分给高权重的机器，直到该机器的权值降到了比其他机器低，才开始将请求分给下一个高权重的机器；
- IP_hash 根据请求者ip的hash值将请求发送到后台服务器中，可以保证来自同一ip的请求被打到固定的机器上，可以解决session的问题。

- url_hash 根据请求的url的hash值将请求分到不同的机器中，当后台服务器为缓存的时候效率高
- fair 根据后台响应时间来分发请求，响应时间短的分发的请求多。

#### 5.3 Nginx解决惊群现象

**惊群现象**：一个网络连接到来，多个睡眠的进程被同时叫醒，但只有一个进程能获得链接，这样会影响系统性能。

Linux内核2.6已经解决了accept时的惊群问题，多个子进程accept堵塞睡眠时，连接到来，只有一个进程的accept会被唤醒返回。但现在子进程的实现方式不是直接accept，而是将初始化好的fd加入到epoll 的事件队列中，epoll返回后再调用accept。Linux无法解决多个子进程epoll返回的情况。这需要子进程自己处理。

Nginx中处理epoll时惊群问题的思路很简单，多个子进程有一个锁，谁拿到锁，谁才将accept的fd加入到epoll队列中，其他的子进程拿不到锁，也就不会将fd加入到epoll中，连接到来也就不会导致所有子进程的epoll被唤醒返回。

#### 5.4 Nginx事件驱动框架

**Nginx事件驱动架构：由一些事件发生源来产生事件，由一个或多个事件收集器来收集事件（epolld）分发事件，许多事件处理器会注册自己感兴趣的事件，同时会消费这些事件。Nginx不会使用进程或线程作为事件消费者，只能是某个模块，当前进程调用模块。**

传统Web服务器（如Apache）的，所谓事件局限在TCP连接建立、关闭上，其他读写都不再是事件驱动，这是会退化成按序执行每个操作的批处理模式，这样每个请求在连接建立后都将始终占用系统资源，直到连接关闭才会释放资源。大大浪费了内存、cpu等资源。并且把一个进程或线程作为事件消费者。

**传统web服务器与Nginx之间的重要差别**： 前者每个事件消费者独占一个进程资源，后者只是被事件分发者进程短期调用而已。

#### 5.5 一个master进程（管理），多个work进程（工作）

master对work进程采用信号进行控制

#### 5.7 Nginx为什么性能高

得益于他的事件处理器：异步非阻塞事件处理机制，运用了epoll模型，提供一个队列排队解决

#### 5.8 Nginx为什么不使用多线程

Apache：创建多个进程或线程，而每个进程或线程都会为其分配cpu和内存并发过大会榨干服务器资源（线程比进程小的多，所以worker支持比perfork高的并发）

Nginx：采用单线程异步非阻塞处理请求（管理员可以配置Nginx主进程的工作进程的数量）（epoll），不会为每个请求分配cpu和内存资源，节省了大量资源，同时也减少了大量的CPU的上下文切换。所以才使得Nginx支持更高的并发。

使用多进程模式，不仅能提高并发率，而且进程之间是相互独立的，一 个worker进程挂了不会影响到其他worker进程。

#### 5.9 Nginx是如何处理一个请求的

- Nginx在启动时，会解析配置文件，得到监听的端口与ip地址，
- 然后在nginx的master进程里初始化这个监控socket， 在进行listen
- 然后在fork出多个子进程出来，子进程会竞争accept新的连接

此时，客户端就可以向Nginx发起连接了，当客户端与Nginx进行三次握手，与Nginx建立好一个连接后

- 某一个子进程会accept成功，然后创建nginx对连接的封装，及ngx_connection_t结构体
- 接着根据事件调用相应的事件处理模块，如http模块与客户端进行数据的交换

最后，nginx或客户端来主动关闭连接。

> 当一个 worker 进程在 accept() 这个连接之后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接，一个完整的请求。一个请求，完全由worker进程来处理，而且只会在一个worker进程中处理。优点：
>
> 节省锁带来的开销。每个worker进程都彼此独立地工作，不共享任何资源，因此不需要锁。同时在编程以及问题排查上时，也会方便很多。
> 独立进程，减少风险。采用独立的进程，可以让互相之间不会影响，一个进程退出后，其它进程还在工作，服务不会中断，master进程则很快重新启动新的worker进程。当然，worker进程自己也能发生意外退出。

#### 5.10 正向代理（代理客户端）

一个位于客户端和原始服务器之间的服务器，为了从原始服务器上获得内容，客户端向代理发送一个请求并指定目标（原始服务器），然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端才能使用正向代理。

#### 5.11 反向代理（代理服务端）

反向代理方式是指以代理服务器来接受internet上的连接请求，然后将请求发送给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器就表现为一个反向代理服务器。

#### 5.12 动静分离

动态资源、静态资源分离是让动态网站里的动态页面根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后，我们就可以根据静态资源的特点将其做缓存操作，这就是网站静态化处理的核心思路。

在我们的软件开发中，有些请求是需要后台处理的（.jsp,.do等），有些请求是不需要经过后台处理的（css、html、jpg、js等）。这些不需要后台处理的文件称为静态文件，否则动态文件。因此我们后台处理忽略静态文件。

动静态分离将网站静态资源和与后台应用分开部署，提高用户访问静态代码的速度，降低对后台应用访问。

#### 5.13 平滑升级

（1）在不停掉老进程的情况下，启动新进程。 （2）老进程负责处理仍然没有处理完的请求，但不再接受处理请求。 （3）新进程接受新请求。 （4）老进程处理完所有请求，关闭所有连接后，停止。

### 6. 遇到的困难

定时任务添加

短链接生成