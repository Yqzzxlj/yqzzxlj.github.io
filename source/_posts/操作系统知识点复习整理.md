---
title: 操作系统知识点复习整理
date: 2021-02-27 20:25:47
tags:
    - 操作系统
    - 基础知识
categories:
    - 计算机基础知识
    - 操作系统
---

## 1. 操作系统基础

### 1.1 什么是操作系统

特征、功能、运行机制

#### 1.1.1 操作系统的特征

1. 并发：两个或多个时间在同一时间间隔内发生。通过分时实现
2. 共享：指系统中的资源可供内存中并发的进程同时使用
3. 虚拟：把一个物理上的实体变为若干个逻辑上的对应物
4. 异步：并发执行时，由于资源有限，进程的执行不是一贯到底而是走走停停。以不可预知的速度向前推进。

#### 1.1.2 操作系统的功能

1. 由上向下：管理分配资源，组织调度计算机的工作（处理器管理，存储器管理、设备管理、文件管理）
2. 由下向上：为用户和其他软件提供接口和环境

#### 1.1.3 运行机制

+ 内核态（管态）：在管态中，操作系统能够访问所有硬件，以及执行任何机器能够运行的命令。能访问所有的内存空间和对象，且所占用的处理机是不允许被抢占的。
+ 用户态（目态）：只用到了机器指令的一个子集。“管理程序”要执行的特权指令不允许在用户态中的程序使用。如I/O指令、置中断指令等影响机器控制的指令。进程所能访问的内存空间和对象受到限制，其所占有的处理机是可被抢占的；
+ 用户态切换到内核态的唯一途径——>中断/异常/陷入（系统调用）

##### 进入内核态的过程

1.用户空间的应用程序，通过系统调用，进入内核空间。这个时候用户空间的进程要传递很多变量、参数的值给内核，内核态运行的时候也要保存用户进程的一些寄存器值、变量等。所谓的“进程上下文”，可以看作是用户进程传递给内核的这些参数以及内核要保存的那一整套的变量和寄存器值和当时的环境等。

2.硬件通过触发信号，导致内核调用中断处理程序，进入内核空间。这个过程中，硬件的一些变量和参数也要传递给内核，内核通过这些参数进行中断处理。所谓的“中断上下文”，其实也可以看作就是硬件传递过来的这些参数和内核需要保存的一些其他环境（主要是当前被打断执行的进程环境）。

### 1.2 什么是系统调用

系统调用运行在系统的内核态。操作系统为用户提供的使用硬件设备的接口服务。

作用：封装了内核，简化的用户程序的开发，用户程序和内核开发的分离，控制开放权限，增强系统稳定性。

## 2. 进程和线程

### 2.1 什么是进程

进程是计算机中处于运行中程序的实体。程序本身只是指令、数据及其组织形式的描述，进程才是程序（指令和数据）的真正运行实例。

#### 1. 进程 = 程序+数据+PCB

> 进程结构一般由3部分组成：代码段、数据段和堆栈段。代码段用于存放程序代码数据，数个进程可以共享同一个代码段。数据段存放程序的全局变量、常量和静态变量。堆栈段中栈用于函数调用，它存放着函数的参数，它存放着函数的参数，函数内部定义的局部变量。堆栈段还包括了进程控制块（Process Control Block， PCB）。PCB处于进程核心堆栈的底部，不需要额外分配空间。PCB时进程存在的唯一标识，系统通过PCB的存在而感知进程的存在

#### 2. linux的PCB：task_struct

+ 所有运行在系统中的进程都以 task_struct 链表的形式存在内核中
+ PCB中的信息
  + 进程描述信息：进程标识符，亲属关系，从属关系（用户，组）
  + 进程控制信息：进程当前状态、进程优先级、程序开始地址，计时信息，通信信息
  + 资源管理信息：代码段指针，数据段指针，堆栈段指针，文件描述符，输入输出设备
  + 处理器调度信息：通用寄存器，地址寄存器，控制寄存器，标志寄存器，状态字

#### 3. 进程的状态

就绪、执行、阻塞、创建、终止。

#### 4. 上下文切换

##### 4.1 上下文

进程上下文指的是记录重启进程或者启动新进程使之活动所有的信息。主要包括括，指向可执行文件的指针,栈,内存(数据段和堆),进程状态, 优先级, 程序I/O的状态, 授予权限, 调度信息, 审计信息, 有关资源的信息(文件描述符和读/写指针), 关事件和信号的信息, 寄存器组(栈指针, 指令计数器)等等, 诸如此类。(当一个进程在执行时,CPU的所有寄存器中的值、进程的状态以及堆栈中的内容被称 为该进程的上下文。)

##### 4.2 上下文切换

上下文切换就是从当前执行任务切换到另一个任务执行的过程。但是，为了确保下次能从正确的位置继续执行，在切换之前，会保存上一个任务的状态。在切换的过程中，操作系统需要先存储当前进程的状态(包括内存空间的指针，当前执行完的指令等等)，再读入下一个进程的状态，然后执行此进程。 进程切换分为两步：
（1）切换页目录以使用新的地址空间
（2）切换内核栈和硬件上下文

- 挂起一个进程，将这个进程的cpu中的状态（上下文）存储于内存中的某处。
- 在内存中检索下一个进程的上下文将其在cpu的寄存器恢复
- 跳转到程序计数器所指向的位置（即跳转到进程被中断时的代码行），以恢复该进程

##### 4.3 进程上下文切换和线程上下文切换的区别

进程上下文切换与线程上下文切换最主要的区别就是线程的切换虚拟空间内存是相同的（因为都是属于自己的进程），但是，进程切换的虚拟空间内存则是不同的。 同时，这两种上下文切换的处理都是通过操作系统内核来完成的。内核的这种切换过程伴随的最显著的性能损耗是将寄存器中的内容切换出。

切换的性能消耗：

1、线程上下文切换和进程上下问切换一个最主要的区别是线程的切换虚拟内存空间依然是相同的，但是进程切换是不同的。这两种上下文切换的处理都是通过操作系统内核来完成的。内核的这种切换过程伴随的最显著的性能损耗是将寄存器中的内容切换出。

2、另外一个隐藏的损耗是上下文的切换会扰乱处理器的缓存机制。简单的说，一旦去切换上下文，处理器中所有已经缓存的内存地址一瞬间都作废了。还有一个显著的区别是当你改变虚拟内存空间的时候，处理的页表缓冲（processor's Translation Lookaside Buffer (TLB)）或者相当的神马东西会被全部刷新，这将导致内存的访问在一段时间内相当的低效。但是在线程的切换中，不会出现这个问题。

### 2.2 进程的创建与结束

进程的创建方式有两种：一种是由操作系统创建，一种是由父进程创建

> 1. 为进程申请一个唯一的进程识别号和空白PCB（PCB是有限的，若PCB申请失败则创建失败）
> 2. 为进程分配资源、为新进程的程序、数据、用户栈分配内存空间（如果资源不足，并不是创建失败，而是处于等待状态，等待资源。
> 3. 初始化PCB，主要包括标志信息、状态信息、处理机信息等。
> 4. 如果就绪队列能够接受新进程，就将进程插入就绪队列中

+ fork函数在新的地址空间里创建进程：拷贝当前进程创建一个子进程。父子进程的区别仅在于PID、PPID、和某些资源和统计量 fork函数不需要参数，返回值是一个进程标识符。fork函数实际上最终是调用clone函数。
+ exec函数负责读取可执行文件并将其载入地址空间开始运行。
+ 子进程完全复制了父进程的地址空间，包括堆栈段和数据段。但是子进程并未复制代码段，而是共用代码段。

**写时拷贝**：传统的fork系统调用直接把所有的资源复制给新创建的进程。Linux中使用写时拷贝，只有在需要写入的时候，数据才会被复制，从而使各个进程拥有各自的拷贝。在此之前只是以只读方式共享。

结束状态：进程从系统中消失，这可能因为正常结束或其他原因中断退出。进程结束时，系统首先置该进程为结束状态，然后进一步释放和回收资源。

> 1. 根据被终止的标识符，检索PCB，从中读取进程状态
> 2. 若进程处于执行状态，立即终止并置标志为真
> 3. 若进程还有子孙进程，则终止子孙进程防止其不可控
> 4. 将终止进程的所有资源释放给系统或父进程
> 5. 将终止进程移除队列

 

### 2.3 僵尸进程、孤儿进程、守护进程

+ 僵尸进程：是指一个进程使用fork创建子进程，如果子进程退出，而父进程没有用wait或waitpid调用子进程的状态信息，子进程的进程描述符仍在系统中，这种进程被成为僵尸进程。
+ 孤儿进程：指一个父进程退出后，而它的一个或多个子进程还在运行，那么那些进程将成为孤儿进程。孤儿进程将被init进程（进程号为1）所收养，并由init进程对他们完成状态收集工作
+ 守护进程：守护进程是脱离于终端在后台运行的进程，守护进程脱离终端是为了避免进程在执行过程中在终端上显示并且不会被终端的信息打断。从被执行时开始运转，整个系统关闭时才退出。

### 2.4 进程间的通信（IPC）

+ 管道：**父子进程**通过管道**单向通信**的机制。没有名字、大小受限、无格式数据。
+ 具名管道：FIFO，使互不相关的进程实现通信，管道可以路径名指定，文件系统可见。
+ 消息队列：以消息链表形式出现，保存消息队列。相比管道独立于进程存在。不需要进程自己提供同步方法。进程有选择的接收消息。
+ 共享内存：允许两个不相关的程序访问同一个逻辑内存。数据共享使进程间不用进行数据传送，没有亲缘关系的要求。但是没有同步机制。
+ socket：套接字也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同机器间的进程通信
+ 信号量：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制
+ 信号：用于通知接收进程某个事件已经发生。

### 2.5 进程的调度

1. 低级调度（进程调度）：根据某种算法，将处理机分配给进程。
2. 中级调度（内存调度）：暂时不能运行的进程挂起，释放内存资源，并把它们调到外存上去等待
3. 高级调度（作业调度）：根据某种算法，把外存上的作业调入内存，并为之创建进程，分配处理机并执行

#### 调度算法

1. 先来先服务（FCFS）：算法简单，但效率低；对长作业比较有利，但对短作业不利（相对SJF 和高响应比）；有利于CPU繁忙型作业，而不利于I/O繁忙型作业。
2. 短作业（进程）优先：对长作业不利，没有考虑紧迫程度
3. 优先级：优先权太低的任务一直就绪，得不到运行，出现“饥饿”现象。
4. 高响应比
5. 时间片轮转：优点: 定时有响应，等待时间较短；缺点: 上下文切换次数较多；
6. 多级反馈队列：时间片轮转算法和优先级调度算法

### 2.6 什么是线程

线程作为CPU调度的基本单位，节省时间（上下文切换）和空间（资源）

### 2.7 多线程同步

1. 互斥锁：互斥锁它有上锁和解锁两个状态。互斥锁一般被设置为全局变量。打开互斥锁可以由某个线程获得，一旦获得，这个互斥锁就会被锁上，只有该线程有权打开其他想要获得互斥锁的线程，会等待直到互斥锁再次打开的时候。
2. 条件变量：条件变量提供了一种线程间的通信机制：当某个共享数据达到某个值的时候，唤醒等待这个共享数据的线程
3. 读写锁：一些程序中存在读者写者问题，某些资源的访问可能出现两种情况，一种是排他性的（独占），另一种操作访问是可以共享的，可以有多个线程同时去访问某个资源。
4. 信号量：互斥锁只允许一个线程进入临界区，而信号量允许多个线程进入临界区。

### 2.8 多线程重入

+ “可重入函数”是指可以由多个函数并发使用而不担心错误的函数。可重入函数可以在任意时刻被中断，稍后在继续运行，且不会丢失数据。
+ 不可重入函数是指只能由一个任务占有，除非能确保函数互斥。

### 2.9 进程和线程的区别

1. **根本区别**：进程是资源分配的基本单位，线程是CPU调度的基本单位。

2. **内存分配**：进程有独立的地址空间，线程不会分配内存，只能共享进程的资源。

3. **资源开销**：进程具有独立的代码和数据空间，开销大；同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器（PC），线程之间切换的开销小。

4. **包含关系**：如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线（线程）共同完成的；线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程。

5. **影响关系**：一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都死掉。所以多进程要比多线程健壮。

   https://blog.csdn.net/u012218309/article/details/81912074

   > 创建线程和进程的步骤一样，只是最终传给clone()函数的参数不同。
   >
   > 在内核中创建的内核线程与普通的进程之间还有个主要区别在于：内核线程没有独立的地址空间，它们只能在内核空间运行。（Linux内核是个单内核）
   >
   > 在 Linux 中进程和线程实际上都是用一个结构体 `task_struct`来表示一个执行任务的实体。进程创建调用`fork` 系统调用，而线程创建则是 `pthread_create` 方法，但是这两个方法最终都会调用到 `do_fork` 来做具体的创建操作 ，区别就在于传入的参数不同。linux根本没有**线程**，它创建的就是进程，只不过通过参数指定多个进程之间共享某些资源（如虚拟内存、页表、文件描述符等），函数调用栈、寄存器等线程私有数据则独立。

   ### 

#### 协程

+ 协程不是被操作系统内核所管理，而完全是由程序所控制（也就是在用户态执行）。 这样带来的好处就是性能得到了很大的提升，不会像线程切换那样消耗资源。协程的开销远远小于线程的开销。
+ 一个线程中可以有任意多个协程，但某一时刻只能有一个协程在运行，多个协程分享该线程分配到的计算机资源。
+ 一旦创建完线程，你就无法决定他什么时候获得时间片，什么时候让出时间片了，你把它交给了内核。而协程编写者可以有可控的切换时机，很小的切换代价。

### 2.10 线程池的使用

（1）高并发、任务执行时间短的业务，线程池线程数可以设置为CPU核数+1，减少线程上下文的切换
（2）并发不高、任务执行时间长的业务要区分开看
　　a）假如是业务时间长集中在IO操作上，也就是IO密集型的任务，因为IO操作并不占用CPU，所以不要让所有的CPU闲下来，可以适当加大线程池中的线程数目，让CPU处理更多的业务
　　b）假如是业务时间长集中在计算操作上，也就是计算密集型任务，这个就没办法了，和（1）一样吧，线程池中的线程数设置得少一些，减少线程上下文的切换

1. 线程池可以减少线程创建和回收的时间。
2. 当线程过多时，会抢占资源，线程池可以控制。
3. 对线程一些简单管理如延迟运行很好控制。

### 2.11 哲学家就餐

### 2.12 读者写者

### 2.13 生产者消费者

## 3. 内存管理

### 3.1 内存管理机制

#### 3.1.1 连续分配

1. 单一连续分配：分配到内存固定区域，只适合单任务系统
2. 固定分区分配：分配到内存中不同的固定区域，分区可以相等也可以不相等。内部碎片
3. 动态分区分配：按程序的需要进程动态划分。外部碎片

##### 空闲内存管理

+ 位图（bitmap）
+ 空闲列表（free lists）

#### 3.1.2 非连续分配

非连续分配（分页/分段）允许一个程序分散地装入到不相邻的内存分区中去

##### 1. 分页管理

内存分为大小固定的块，按物理结构划分，会有内部碎片

+ 进程中的块称为**页**，内存中的块称为**页框**。进程在执行时需要申请主存空间，就是要为每个页面分配主存中的可用页框。
+ 地址结构：页面+页内偏移量
+ 页表： 为了便于在内存中找到进程的每个页面所对应的物理块，系统为每个进程建立一张页表，记录页面在内存中对应的物理块号。页表一般放在内存中。若页表全部放在内存中，则存取一条数据或指令至少需要访问两次内存：一次访问页表，确定物理地址，第二次存取数据或指令

##### 2. 分段管理

内存块的大小不固定，按逻辑结构划分，会有外部碎片

段式管理方式按照用户进程中的自然段划分逻辑空间（段内要求连续，段间不要求连续）

##### 3.段页式管理

基本分段和基本分页的结合，会有内部碎片。

作业的地址空间首先被分为若干个逻辑段，每一段再被分为若干个大小固定的页。

### 3.2 快表和多级页表

1. 每次访问操作都需要进行逻辑地址到物理地址的转换，**地址转换过程必须足够快，否则访存速度会降低**
2. 每个进程引入了页表，用于存储映射机制，**页表不能太大，否则内存利用率会降低**

+ 快表/联想寄存器/TLB 在地址变换机构中的一个具有并行查找能力的高速缓冲存储器。用来存放当前访问的若干页表项，以加速地址变换的过程。主存中的页表称为慢表。

+ 多级页表 一级页号+二级页号+业内偏移

### 3.3 分页机制和分段机制的区别、共同点

非连续分配。寻址方式类似。

+ 分页产生内部碎片，分段产生外部碎片；
+ 分页地址1维，分段地址2维。
+ 分页按物理结构划分，大小固定；分段按逻辑结构划分，大小不固定

### 3.4 逻辑地址和物理地址

+ 物理地址：加载到内存地址寄存器中的地址，内存单元的真正地址。
+ 逻辑地址：CPU生成的地址。逻辑地址是内部和编程使用的、并不唯一。它是相对于你当前进程数据段的地址（偏移地址），不和绝对物理地址相干。

### 3.5 CPU寻址

快表->慢表（内存->硬盘）->物理地址

### 3.6 虚拟内存

#### 3.6.1 虚拟内存的作用

1. 虚拟内存将主存储器看成一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存储器之间来回传送数据。
2. 为每个进程提供了一致的地址空间。
3. 保护了每个进程的地址空间不被其他进程破坏。

随着软件的不断增大，需要运行的程序往往大到内存无法容纳。应用交换技术并不是很高效（交换几GB的内存）。

虚拟内存使用了外存上的空间来扩充内存的空间，通过一定的换入换出，使得整个系统在逻辑上能够使用一个远远超出其物理内存大小的内存容量。

- 虚拟存储器：对物理存储器的抽象，**允许程序申请大于实际物理存储的内存**，提供一致性的地址空间。基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其余部分留在外存，就可以启动程序执行。在程序执行过程中，当所访问的信息不在内存时，由操作系统讲所需要的部分调入内存，然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换出到外存上，从而腾出空间存放要掉入内存的信息。这样，系统好像为用户提供了一个比实际内存大得多的存储器，称为虚拟存储器。
- 内存管理单元（Memory Management Unit， MMU），MMU把虚拟地址映射为物理内存地址。

#### 3.6.2 局部性原理

- 时间局部性：如果一条指令被执行或某个数据被访问过，那么不久以后该指令可能再次执行，该数据可能再次被访问
- 空间局部性：如果某个单元被访问过，那么不久之后它周围的空间也会被访问。

#### 3.6.3 特征：

1. 多次性， 无需在作业时一次性全部装入内存，而是允许被分成多次调入内存运行
2. 对换性，无需在作业运行时一直常驻内存，允许在作业的运行过程中，进行换进和换出
3. 虚拟性，从逻辑上扩充内存的容量，用户看到的内存容量，远大于实际的内存容量

#### 3.6.4虚拟内存技术的实现

- 一定容量的内存和外存
- 页表机制（或段表机制），作为主要的数据结构
- 中断机构，当用户程序访问到的部分尚未调入内存，则产生中断
- 地址变换机构（MMU），逻辑地址到物理地址的变换

### 3.7 页面置换算法

1. 最佳页面置换算法：以后最长时间不访问的置换出
2. 先进先出算法
3. LRU（最久未访问）算法：需要有寄存器或栈的支持。(实现方法：双向链表+hashmap)
4. LFU（最不频繁使用）算法：两个双向链表+hash
5. CLOCK算法：循环扫描缓冲区，像时钟的针一样转动。给每一帧关联一个使用位。当缺页错误出现时，首先检查指针指向的页面，如果R位是0就淘汰页面，并把新页面插入，然后表针前移；如果R位是1就清零前移。

## 4. 死锁

多个进程因为竞争资源而造成的互相等待的僵局。

### 4.1 死锁的四个条件

1. 互斥：进程需要独占资源
2. 不剥夺：进程所获资源未使用结束之前，不会被其他进程强行夺走
3. 请求和保持：请求资源失败时不会释放已获得资源
4. 循环等待：存在进程的循环等待链。

### 4.2 死锁的处理策略

破坏四个条件。

+ 鸵鸟策略：解决死锁问题，代价很高，所以不去解决。
+ 预防：银行家算法。将操作系统看作银行家，资源看作资金。每次进程请求资源时，系统会评估进程的最大需求资源，检查资源分配后系统是否处于安全状态，来决定是否分配资源。
+ 检测：资源分配图简化。在图中找到既不阻塞有不是孤点的进程p。如果它请求的资源小于系统空闲资源，则消除其请求边和分配边，使之成为孤点。如果死锁发生，该图不可完全简化。

### 4.3 悲观锁和乐观锁

+ 悲观锁：它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度(悲观)，因此，在整个数据处理过程中，将数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制.比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。
+ 乐观锁：总认为不会产生问题，每次取数据的时候总认为不会有其他线程对数据进行修改。不会上锁，但在更新时会判断其他线程在这之前有没有对数据进行过修改。比较适合读取操作比较频繁的场景，如果出现大量的写入操作，数据发生冲突的可能性就会增大，为了保证数据的一致性，应用层需要不断的重新获取数据，这样会增加大量的查询操作，降低了系统的吞吐量。
+ 乐观锁实现方式：1. 数据版本记录机制。2. CAS（compare and swap）算法，会有ABA问题。

